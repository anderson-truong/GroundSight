{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9a278c-78f5-40c6-8289-b30c0f2500be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9f02d5-1d82-445e-83bf-65fc332f09d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mnist \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\n\u001b[0;32m      2\u001b[0m (train_images, train_labels), (test_images, test_labels) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(train_images[\u001b[38;5;241m2\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "plt.imshow(train_images[2], cmap='gray')\n",
    "\n",
    "test_image = train_images[2]\n",
    "\n",
    "train_images = train_images.astype(np.float32) / 255\n",
    "test_images = test_images.astype(np.float32) / 255\n",
    "train_images = np.expand_dims(train_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53418d9f-c2e0-4c16-940f-494d2dd327b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 13, 13, 6)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 11, 11, 6)         330       \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 726)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                7270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,660\n",
      "Trainable params: 7,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flami\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3050 - accuracy: 0.9114 - val_loss: 0.1362 - val_accuracy: 0.9620\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1115 - accuracy: 0.9657 - val_loss: 0.0906 - val_accuracy: 0.9747\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0834 - accuracy: 0.9751 - val_loss: 0.0837 - val_accuracy: 0.9749\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0690 - accuracy: 0.9789 - val_loss: 0.0731 - val_accuracy: 0.9783\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0619 - accuracy: 0.9809 - val_loss: 0.0659 - val_accuracy: 0.9806\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.0681 - val_accuracy: 0.9799\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0491 - accuracy: 0.9849 - val_loss: 0.0624 - val_accuracy: 0.9820\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.0695 - val_accuracy: 0.9796\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.0609 - val_accuracy: 0.9821\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0620 - val_accuracy: 0.9822\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0597 - val_accuracy: 0.9833\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0597 - val_accuracy: 0.9833\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 0.0616 - val_accuracy: 0.9825\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0594 - val_accuracy: 0.9822\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0278 - accuracy: 0.9916 - val_loss: 0.0581 - val_accuracy: 0.9833\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0633 - val_accuracy: 0.9825\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0640 - val_accuracy: 0.9833\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0688 - val_accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.0672 - val_accuracy: 0.9826\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0669 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23614cc2d10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "input_shape = (28, 28, 1)\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(6, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(6, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f986514-dc02-4400-9dca-2615ab63278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.9844\n",
      "Test accuracy: 0.9843999743461609\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86f285db-1418-4c75-ac3f-926910697da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 13, 13, 6)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 11, 11, 6)         330       \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 726)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                7270      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,660\n",
      "Trainable params: 7,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9844\n",
      "Restored model, accuracy: 98.44%\n",
      "Restored model, loss: 0.05882437899708748\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "print(\"Restored model, loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfc59ef1-8be0-475f-85c0-254346c91cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist-tflite\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist-tflite\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist-tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9202f94-c256-4434-bd6d-c8cd89f3dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model is 11592 bytes\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('mnist-tflite')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_size = open('./mnist_model.tflite', \"wb\").write(tflite_model)\n",
    "print(\"Quantized model is %d bytes\" % tflite_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b92711-3ebb-4c94-9f28-63af3f290179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/microcontrollers/build_convert\n",
    "# xxd -i mnist_model.tflite > model_data.cc\n",
    "\n",
    "# Helpful for Git Bash https://gist.github.com/evanwill/0207876c3243bbb6863e65ec5dc3f058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9220835-3330-4669-a13a-ca3b94020613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_input_3:0\n",
      "shape: [ 1 28 28  1]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "DUMP INPUT\n",
      "{'name': 'serving_default_input_3:0', 'index': 0, 'shape': array([ 1, 28, 28,  1]), 'shape_signature': array([-1, 28, 28,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "\n",
      "DUMP OUTPUT\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 15, 'shape': array([ 1, 10]), 'shape_signature': array([-1, 10]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='./mnist_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", interpreter.get_input_details()[0]['name'])\n",
    "print(\"shape:\", interpreter.get_input_details()[0]['shape'])\n",
    "print(\"type:\", interpreter.get_input_details()[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", interpreter.get_output_details()[0]['name'])\n",
    "print(\"shape:\", interpreter.get_output_details()[0]['shape'])\n",
    "print(\"type:\", interpreter.get_output_details()[0]['dtype'])\n",
    "\n",
    "print(\"\\nDUMP INPUT\")\n",
    "print(interpreter.get_input_details()[0])\n",
    "print(\"\\nDUMP OUTPUT\")\n",
    "print(interpreter.get_output_details()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9602d497-b3f9-4409-a5fc-e26d9232d730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24608"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\".\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9af0604-5f85-4744-97e2-cedaadbd8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"../tensorflow-lite-esp32/firmware/src/digit.h\",\"w\")\n",
    "f.write(\"const float digit[] = { \\n\")\n",
    "for d in test_image.flatten():\n",
    "    f.write(str(d))\n",
    "    f.write(',')\n",
    "f.write('\\n};')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798540f-69b3-4fea-b005-7bde6193cea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
